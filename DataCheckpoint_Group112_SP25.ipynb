{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you lost points on the last checkpoint you can get them back by responding to TA/IA feedback**  \n",
    "\n",
    "Update/change the relevant sections where you lost those points, make sure you respond on GitHub Issues to your TA/IA to call their attention to the changes you made here.\n",
    "\n",
    "Please update your Timeline... no battle plan survives contact with the enemy, so make sure we understand how your plans have changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Tyler Hoang\n",
    "- Tanner Berman\n",
    "- Thanh Hoang\n",
    "- David Villalobos Hornback\n",
    "- Manjot Samra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Include a specific, clear data science question.\n",
    "-  Make sure what you're measuring (variables) to answer the question is clear\n",
    "\n",
    "What is your research question? Include the specific question you're setting out to answer. This question should be specific, answerable with data, and clear. A general question with specific subquestions is permitted. (1-2 sentences)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our research question:** Do American Congressmen in industry or commerce-related committees trading stocks related to their sector perform better than when investing in unrelated sectors?\n",
    "\n",
    "**Details**: \n",
    "We want to investigate the following committees:\\\n",
    "House: Energy & Commerce\\\n",
    "- Senate Equivalent: Commerce, Science, and Transportation + Energy and Natural Resources\\\n",
    "House: Financial Services\\\n",
    "- Senate Equivalent: Banking, Housing, and Urban Affairs\\\n",
    "House: Science, Space, and Technology\\\n",
    "- Senate Equivalent: Commerce, Science, and Transportation\\\n",
    "House: Armed Services\\\n",
    "- Senate Equivalent: Armed Services\\\n",
    "House: Transportation and Infrastructure\\\n",
    "- Senate Equivalent: Environment and Public Works + Commerce (Transportation Subcommittee)\\\n",
    "House: Agriculture\\\n",
    "- Senate Equivalent: Agriculture, Nutrition, and Forestry\\\n",
    "House: Ways and Means\\\n",
    "- Senate Equivalent: Finance\\\n",
    "House: Judiciary\\\n",
    "- Senate Equivalent: Judiciary\t\\\n",
    "House: Education and the Workforce\t\\\n",
    "- Senate Equivalent: Health, Education, Labor and Pensions (HELP)\t\\\n",
    "House: Homeland Security\t\\\n",
    "- Senate Equivalent: Homeland Security and Governmental Affairs\n",
    "\t\n",
    "Independent Variable: Whether the stock is related or unrelated to the politicians committee focus (Related vs. Unrelated Sector). We may also investigate patterns related to state, commitee, or party\\\n",
    "Dependent Variable: Performance (ROI) of stock after a set period of time (e.g., weekly, monthly, yearly)\\\n",
    "Population: House and Senate members of key committees\\\n",
    "Control Variables: Market Return, sector return overall, stock volatility, trade size\\\n",
    "Timeframe: 3 Years to current date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Include a general introduction to your topic\n",
    "- Include explanation of what work has been done previously\n",
    "- Include citations or links to previous work\n",
    "\n",
    "This section will present the background and context of your topic and question in a few paragraphs. Include a general introduction to your topic and then describe what information you currently know about the topic after doing your initial research. Include references to other projects who have asked similar questions or approached similar problems. Explain what others have learned in their projects.\n",
    "\n",
    "Find some relevant prior work, and reference those sources, summarizing what each did and what they learned. Even if you think you have a totally novel question, find the most similar prior work that you can and discuss how it relates to your project.\n",
    "\n",
    "References can be research publications, but they need not be. Blogs, GitHub repositories, company websites, etc., are all viable references if they are relevant to your project. It must be clear which information comes from which references. (2-3 paragraphs, including at least 2 references)\n",
    "\n",
    " **Use inline citation through HTML footnotes to specify which references support which statements** \n",
    "\n",
    "For example: After government genocide in the 20th century, real birds were replaced with surveillance drones designed to look just like birds.<a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1) Use a minimum of 2 or 3 citations, but we prefer more.<a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2) You need enough to fully explain and back up important facts. \n",
    "\n",
    "Note that if you click a footnote number in the paragraph above it will transport you to the proper entry in the footnotes list below.  And if you click the ^ in the footnote entry, it will return you to the place in the main text where the footnote is made.\n",
    "\n",
    "To understand the HTML here, `<a name=\"#...\"> </a>` is a tag that allows you produce a named reference for a given location.  Markdown has the construciton `[text with hyperlink](#named reference)` that will produce a clickable link that transports you the named reference.\n",
    "\n",
    "1. <a name=\"cite_note-1\"></a> [^](#cite_ref-1) Lorenz, T. (9 Dec 2021) Birds Aren’t Real, or Are They? Inside a Gen Z Conspiracy Theory. *The New York Times*. https://www.nytimes.com/2021/12/09/technology/birds-arent-real-gen-z-misinformation.html \n",
    "2. <a name=\"cite_note-2\"></a> [^](#cite_ref-2) Also refs should be important to the background, not some randomly chosen vaguely related stuff. Include a web link if possible in refs as above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our response:\n",
    "**Background Research & Prior Work**\n",
    "In the United States, lawmakers have long faced public criticism for alleged insider trading. Insider trading happens when an individual purchases or sells an asset that they own based on information that is not known to the public, often because they have access to the company's financial information or even plans. For U.S. lawmakers, this means that they have non-public information because of legislative work or committee briefings that they are a part of. They govern laws that may affect an entire industry or a subsector of that industry. To address the issues of insider trading, Congress passed the Stop Trading on Congressional Knowledge Act, also known as the STOCK Act, on April 3, 2012, which requires U.S. Lawmakers to announce/show trades (buying/selling) exceeding $1,000 public information within 30–45 days of the transaction.<a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1) Despite this, it is still debated whether this act really stopped insider trading, or does it allow it to happen in plain sight. This critique encourages the debate whether the STOCK Act has actively/effectively deterred insider trading and further encourages our research question to determine if politicians are getting better ROI's on stocks related to their sectors potentially due to insider knowledge of their sector.\n",
    "\n",
    "Studies have analyzed stock and trade data to investigate whether members of Congress consistently do better or outperform the market with their trades. Ziobrowski et al. (2011) analyzed over 16,000 transactions made by House Members between 1985 and 2001, finding that if you copied their trade portfolio, you would have outperformed the market by 6.6%.<a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2) But more recent research by Belmont et al. (2022), which looked at all trades from January 2012 to December 2020 (post-STOCK Act) made by U.S. lawmakers, found no evidence of lawmakers having a trading advantage: buy trades underperformed the market by 26 basis points and sell trades by 11 basis points over a period of six months.<a name=\"cite_ref-3\"></a>[<sup>3</sup>](#cite_note-3) Meanwhile, Quiver Quantitative’s “Pelosi Tracker” shows that mimicking Nancy Pelosi’s disclosed trades since May 16, 2014, would have produced returns of around 720%, compared to approximately 230% for the S&P 500 over the same period.<a name=\"cite_ref-4\"></a>[<sup>4</sup>](#cite_note-4) However, these results don’t account for trading costs, taxes, or delays in disclosure. These differences show how results can vary depending on time period, methodology, and individual lawmakers. Our project builds on this prior work by asking a more specific question, wether lawmakers perform better when trading stocks from sectors tied to their committee assignments.\n",
    "\n",
    "An article by Jack Caporal from The Motley Fool looks at congressional stock trading patterns between 2021 and 2024 and shows that more than 100 members of Congress made around 10,000 stock trades per year.<a name=\"cite_ref-5\"></a>[<sup>5</sup>](#cite_note-5) In 2024 alone, the average estimated returns were 31.1% for Democrats and 26.1% for Republicans. The most commonly traded companies were Microsoft, Apple, Nvidia, JPMorgan Chase, and Palo Alto Networks. Many of these trades happened around the same time as major legislation, like the CHIPS and Science Act or the TikTok divestment bill. This raises questions about whether members of Congress may be trading from the information they have access to through their legislative work and connections. The article also highlights that members often trade stocks in industries related to the committees they serve on, like defense, health, and energy. This supports our project’s focus beucase it shows us whether politicians see stronger returns when they trade stocks related to the sectors they oversee. It also shows that there’s already public interest and growing concern about whether these trades are ethical.\n",
    "\n",
    "A study co-authored by Dinesh Hasija, PhD, who is an assitant professor of management at Augusta University, in the Hull College of Business, looked at how the stock market reacts to trades made by U.S Senators.<a name=\"cite_ref-6\"></a>[<sup>6</sup>](#cite_note-6) The study found that investors tend to believe that members of Cngress have insider knowledge and influence over certain compainies, especially when they oversee those industries. Because of this, the market react positively when the stock trades of those members in congress are made public. And the effect is even stronger when the firm is tied to members of U.S. Senate through lobbying-sponsored legislation and politcal action committee contributions. This finding shows that the trades made by lawmakers or the members of Congress with direct oversight roles lead to bigger market reactions, which supporst our project's hypothesis: that comitte assignments might play a role in stock performance.\n",
    "\n",
    "Lastly, another study by Nantiya Udomworarat, a researcher from the number one research university in Thailand and was published by the university, Chulalongkorn University in 2005.<a name=\"cite_ref-7\"></a>[<sup>7</sup>](#cite_note-7) The conducted research project aimed to discover \"the relationship between politics and stock returns in Stock Exchange of Thailand (SET).\" It was concluded that political connections typically don't lead to greater statistically significant returns in the market. However, in  support of out hypothesis, they found that \"stock returns increased 43.35% in 2003 when the firms were connected in someway to the politcal cabinet. Additionally, they found that the returns of firms who were connected to a cabinet and firms connected to politicians perform better than non-connected firms. They author also found that both \"abnormal returns of connected firms and those of non-connected firms\" tend to behave similarly regardless of the situation. Some limitations of the source includes where it was conducted (in Thailand), its age, and the fact that it concluded there was not typically a difference in returns based on politcal cabinet. However, we believe that the other findings may support our hypothesis, even in the U.S, and we aim to discover if this can be applied to different nations.\n",
    "\n",
    "1. <a name=\"cite_note-1\"></a> [^](#cite_ref-1) Adam Hayes (April 16, 2025) STOCK Act: Meaning, Overview, Criticisms. <i>Investopedia</i>. https://www.investopedia.com/terms/s/stop-trading-on-congressional-knowledge-act.asp\n",
    "\n",
    "2. <a name=\"cite_note-2\"></a> [^](#cite_ref-2) Ziobrowski, A. J., Boyd, J. W., Cheng, P., & Ziobrowski, B. J. (April, 2011) Abnormal Returns from the Common Stock Investments of Members of the U.S. House of Representatives. <i>Lindenwood University</i>. https://digitalcommons.lindenwood.edu/faculty-research-papers/240/\n",
    "\n",
    "3. <a name=\"cite_note-3\"></a> [^](#cite_ref-3) Belmont, A., Hutton, I., & Jacobsen, R. (November 17, 2021,) Do U.S. Lawmakers Have an Edge in Stock Trading? <i>Science Direct</i>. https://www.sciencedirect.com/science/article/abs/pii/S0047272722000044\n",
    "\n",
    "4. <a name=\"cite_note-4\"></a> [^](#cite_ref-4) Pelosi Tracker – Quiver Quantitative. <i>Quiver Quantitative</i>. https://www.quiverquant.com/congresstrading/politician/Nancy%20Pelosi-P000197\n",
    "\n",
    "5. <a name=\"cite_note-5\"></a> [^](#cite_ref-5) Jack Caporal (Jan 31, 2025) Congressional Stock Trading: Who Trades and Makes the Most. <i>The Motley Fool</i>. https://www.fool.com/research/congressional-stock-trading-who-trades-and-makes-the-most/\n",
    "\n",
    "6. <a name=\"cite_note-6\"></a> [^](#cite_ref-6) Kevin Faigle & Dinesh Hasija (Oct 18, 2022). New Study Shows Congressional Stock Purchases May Impact Stock Market Reactions. <i>Jagwire</i>. https://jagwire.augusta.edu/new-study-shows-congressional-stock-purchases-may-impact-stock-market-reactions/\n",
    "\n",
    "7. <a name=\"cite_note-7\"></a> [^](#cite_ref-7) Nantiya Udomworarat (2005) Politics and Stock Returns: Evidence from Thailand. <i>Chulalongkorn University</i> https://doi.org/10.14457/cu.the.2005.1604"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Include your team's hypothesis\n",
    "- Ensure that this hypothesis is clear to readers\n",
    "- Explain why you think this will be the outcome (what was your thinking?)\n",
    "\n",
    "What is your main hypothesis/predictions about what the answer to your question is? Briefly explain your thinking. (2-3 sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our response:\n",
    "**Hypotheis:**\n",
    "We predict that trades made by politicians in sectors related to their committees will show a moderate positive correlation with three-month return on investment. Specifically, we expect these related trades to outperform unrelated trades by at least 10 percentage points in three-month ROI on average.\n",
    "\n",
    "**Hypothesis Clarification:**\n",
    "ROI here means how much the stock's price changes three months after it was bought, showing whether it gained or lost value.\n",
    "\n",
    "**Hypothesis Reasoning:**\n",
    "Politicians who oversee a sector might have greater knowledge or insider information about that industry. We believe this could help them make stock decisions that are more profitable within that sector, compared to other sectors. However, it is more likely that greater knowledge leads to better trades, and it is hard to draw conclusions about the true cause of better performing investment returns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data overview\n",
    "\n",
    "For each dataset include the following information\n",
    "- Dataset #1\n",
    "  - Dataset Name:\n",
    "  - Link to the dataset:\n",
    "  - Number of observations:\n",
    "  - Number of variables:\n",
    "- Dataset #2 (if you have more than one!)\n",
    "  - Dataset Name:\n",
    "  - Link to the dataset:\n",
    "  - Number of observations:\n",
    "  - Number of variables:\n",
    "- etc\n",
    "\n",
    "Now write 2 - 5 sentences describing each dataset here. Include a short description of the important variables in the dataset; what the metrics and datatypes are, what concepts they may be proxies for. Include information about how you would need to wrangle/clean/preprocess the dataset\n",
    "\n",
    "If you plan to use multiple datasets, add a few sentences about how you plan to combine these datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Response:\n",
    "\n",
    "## Data overview\n",
    "\n",
    "For each dataset include the following information\n",
    "- Dataset #1\n",
    "  - Dataset Name: __Quiver Quantitative Congress Trading - Full History__\n",
    "  - Link to the dataset: __https://github.com/COGS108/Group112_SP25/blob/master/congress-trading-all.xlsx__\n",
    "  - Number of observations: __51294__\n",
    "  - Number of variables: __20__\n",
    "- Dataset #2 (if you have more than one!)\n",
    "  - Dataset Name: __Capitol Trades__\n",
    "  - Link to the dataset: __https://github.com/COGS108/Group112_SP25/blob/master/dataset_capitol-trades-scraper_2025-05-12_17-38-39-324.csv__\n",
    "  - Number of observations: __10156__\n",
    "  - Number of variables: __13__\n",
    "\n",
    "Now write 2 - 5 sentences describing each dataset here. Include a short description of the important variables in the dataset; what the metrics and datatypes are, what concepts they may be proxies for. Include information about how you would need to wrangle/clean/preprocess the dataset\n",
    "\n",
    "If you plan to use multiple datasets, add a few sentences about how you plan to combine these datasets.\n",
    "\n",
    "\n",
    "### Dataset 1 Description:\n",
    "- The dataset shows stock trades disclosed by members of the U.S. Congress. Some of the important variables are the ticker symbol/company shorthand (Ticker), the type of asset (ex. Crypto, stock, bond, etc.) (TickerType), company name (Company), transaction type (Transaction), trade date (Traded), estimated trade value (Trade_Size_USD) but this last one may not be useful for us. Some of the important variables considering the politician are the politician’s name (Name), politician’s chamber (Chamber), and the politician’s party affiliation (Party). The (excess_return) column will be very helpful to us because it is the calculated performance of the stock relative to the market after the trade, which is the key metric for determining how profitable it was; it will serve as a proxy for determining a measurement of a Congressperson’s success in the market. Here are some important wrangle/cleaning/preprocess considerations: Tickers with special characters (ex: BRK/B, need to be dealt with), Ticker and Sector matching (we have good progress on this), Congressperson and Sector matching, removing unnecessary variables, cleaning up blank values, and identifying trades related to a Congressman’s sector.\n",
    "\n",
    "### Dataset 2 Description:\n",
    "- This dataset contains information about stock trades by US Congress members. Some key variables are the names of the politicians, (politician_name), and their party affiliation, (politican_family), and the date when the trades happened, (traded, what the actual company being traded is, (traded_issuer_name), the ticker symbol, (traded_issuer_ticker), the price of the share price at the trade time, (price), transaction type, buy or sell, (type). This dataset may be used to proxy for success in investment based on the return on investment. We need to calculate ROI by matching buy transactions and sell transactions. We also need to remove rows that have missing data, dealing with tickers with special characters, removing unused variables, and identifying trade related to Congressman’s sector.\n",
    "\n",
    "\n",
    "### Combining Datasets:\n",
    "- If we choose to, we will combine datasets by only including important identifying information in each entry. Namely, we will include the ticker name, the ROI, the sector that the stock’s company belongs to, the Congressman, the sector that the Congressman’s committee belongs to, the date of the trade, as well as the Congressman’s party affiliation. We will identify identical entries (same politician, stock, and date traded), and only take one of these values in our final result.\n",
    "However, we will probably not be combining datasets, as we plan to use one dataset for EDA, and the other for the full-on analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset #1 (Quiver Quantitative Congress Trading - Full History)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "\n",
    "import time, random, requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "data = pd.read_excel(\"FINAL_dataset.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use same program as below to scrape for ticker sectors & industries\n",
    "# TODO: associate congressman w/ industry\n",
    "\n",
    "# most of our wrangling work has been done on Dataset #2 as it required more modification to be usable, however we can reuse many functions on Dataset #1 to finish it quickly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset #2 (Capitol Trades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"EDA_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched 1,164 round-trip trades\n",
      "   politician_name    ticker   buy_date  sell_date  days_held  buy_price  \\\n",
      "0     Ashley Moody    HWM:US 2025-01-22 2025-02-24         33     126.71   \n",
      "1  Bruce Westerman   AAPL:US 2025-03-03 2025-03-20         17     238.03   \n",
      "2  Bruce Westerman   AMZN:US 2025-03-03 2025-03-20         17     205.02   \n",
      "3  Bruce Westerman   AVGO:US 2025-03-03 2025-03-20         17     187.37   \n",
      "4  Bruce Westerman  GOOGL:US 2025-03-03 2025-03-20         17     167.01   \n",
      "\n",
      "   sell_price  size_buy size_sell  pct_return  \n",
      "0      129.56  50K–100K  50K–100K    2.249231  \n",
      "1      214.10   15K–50K    1K–15K  -10.053355  \n",
      "2      194.95   15K–50K    1K–15K   -4.911716  \n",
      "3      190.54    1K–15K    1K–15K    1.691840  \n",
      "4      162.80   15K–50K    1K–15K   -2.520807  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# CLEAN  -----------------------------------------------------------\n",
    "# unify case in the action column\n",
    "df['type'] = df['type'].str.lower().str.strip()        # 'buy' / 'sell'\n",
    "\n",
    "# convert traded date to datetime\n",
    "df['trade_date'] = pd.to_datetime(df['traded'], dayfirst=True, errors='coerce')\n",
    "\n",
    "df['price'] = df['price'].replace(['N/A', 'n/a', 'NA', 'na'], np.nan)\n",
    "\n",
    "# clean price -> float  (drops $ and commas)\n",
    "df['trade_price'] = (\n",
    "    df['price']\n",
    "      .str.replace(r'[\\$,]', '', regex=True)\n",
    "      .astype(float)\n",
    ")\n",
    "\n",
    "df = df.dropna(subset=['trade_price'])\n",
    "\n",
    "# keep only rows that parsed correctly\n",
    "df = df.dropna(subset=['trade_date', 'trade_price'])\n",
    "\n",
    "# sort so merge / iteration is deterministic\n",
    "df = df.sort_values(['politician_name',\n",
    "                     'traded_issuer_ticker',\n",
    "                     'trade_date'])\n",
    "\n",
    "# MATCH  BUYS ↔ SELLS  ---------------------------------------------\n",
    "pairs = []                    # will collect one dict per matched trade\n",
    "\n",
    "for (member, ticker), g in df.groupby(['politician_name',\n",
    "                                       'traded_issuer_ticker']):\n",
    "    \n",
    "    buys  = g[g['type'] == 'buy'].copy().reset_index(drop=True)\n",
    "    sells = g[g['type'] == 'sell'].copy().reset_index(drop=True)\n",
    "    \n",
    "    # pointers for a simple one-to-one FIFO match\n",
    "    i = j = 0\n",
    "    while i < len(buys) and j < len(sells):\n",
    "        buy_row  = buys.loc[i]\n",
    "        \n",
    "        # move j forward until we find a SELL *after* this BUY\n",
    "        while j < len(sells) and sells.loc[j, 'trade_date'] <= buy_row['trade_date']:\n",
    "            j += 1\n",
    "        if j == len(sells):         # no more sells after this buy\n",
    "            break\n",
    "        \n",
    "        sell_row = sells.loc[j]\n",
    "\n",
    "        pairs.append({\n",
    "            'politician_name'  : member,\n",
    "            'ticker'           : ticker,\n",
    "            'buy_date'         : buy_row['trade_date'],\n",
    "            'sell_date'        : sell_row['trade_date'],\n",
    "            'days_held'        : (sell_row['trade_date'] - buy_row['trade_date']).days,\n",
    "            'buy_price'        : buy_row['trade_price'],\n",
    "            'sell_price'       : sell_row['trade_price'],\n",
    "            'size_buy'         : buy_row.get('size', np.nan),\n",
    "            'size_sell'        : sell_row.get('size', np.nan),\n",
    "            # simple % return (use midpoint of size band, exact shares, etc. if you have it)\n",
    "            'pct_return'       : (sell_row['trade_price'] - buy_row['trade_price'])\n",
    "                                 / buy_row['trade_price'] * 100\n",
    "        })\n",
    "        \n",
    "        # advance both pointers for a one-to-one match\n",
    "        i += 1\n",
    "        j += 1\n",
    "\n",
    "# RESULT  ----------------------------------------------------------\n",
    "pair_df = pd.DataFrame(pairs)\n",
    "pair_df.to_csv('ROI_EDA_dataframe.csv', index=False, sep=',', encoding='utf-8')\n",
    "\n",
    "print(f\"Matched {len(pair_df):,} round-trip trades\")\n",
    "print(pair_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$AERO', '$BTC', '$ETH', '$GRT', '$SKI', '$SOL', '$VELO', '$VIRTUAL', '$XRP', 'A:US', 'AA:US', 'AAGIY:US', 'AAL:US', 'AAON:US', 'AAPL:US', 'AAXJ:US', 'ABB:US', 'ABBV:US', 'ABCB:US', 'ABEV:US', 'ABNB:US', 'ABT:US', 'ACGL:US', 'ACI:US', 'ACN:US', 'ADBE:US', 'ADDYY:US', 'ADI:US', 'ADM:US', 'ADP:US', 'ADRNY:US', 'ADSK:US', 'AEE:US', 'AEIS:US', 'AEP:US', 'AER:US', 'AES:US', 'AESI:US', 'AFL:US', 'AGCO:US', 'AGIO:US', 'AIG:US', 'AIQUY:US', 'AIT:US', 'AIZ:US', 'AJG:US', 'AKAM:US', 'ALB:US', 'ALC:US', 'ALE:US', 'ALFVY:US', 'ALG:US', 'ALGM:US', 'ALGN:US', 'ALGT:US', 'ALIZY:US', 'ALK:US', 'ALKT:US', 'ALL:US', 'ALLY:US', 'AMAT:US', 'AMCR:US', 'AMD:US', 'AME:US', 'AMGN:US', 'AMP:US', 'AMSF:US', 'AMT:US', 'AMTM:US', 'AMZN:US', 'ANET:US', 'ANSS:US', 'AON:US', 'AOS:US', 'APD:US', 'APG:US', 'APH:US', 'APO:US', 'APP:US', 'APPF:US', 'APTV:US', 'AR:US', 'ARE:US', 'ARES:US', 'ARIS:US', 'ARLP:US', 'ARMK:US', 'ARW:US', 'ASAZY:US', 'ASC:US', 'ATKR:US', 'ATLKY:US', 'ATO:US', 'ATR:US', 'ATRC:US', 'AVB:US', 'AVGO:US', 'AVTR:US', 'AVY:US', 'AWK:US', 'AXON:US', 'AXP:US', 'AXTA:US', 'AZN:US', 'AZO:US', 'AZTA:US', 'BA:US', 'BABA:US', 'BAC:US', 'BAH:US', 'BALL:US', 'BATRA:US', 'BAX:US', 'BAYRY:US', 'BBEU:US', 'BBVA:US', 'BBWI:US', 'BBY:US', 'BC:US', 'BCS:US', 'BDRFY:US', 'BDX:US', 'BECN:US', 'BEN:US', 'BERY:US', 'BF/A:US', 'BG:US', 'BHP:US', 'BIIB:US', 'BITB:US', 'BJ:US', 'BK:US', 'BKE:US', 'BKNG:US', 'BKR:US', 'BLDR:US', 'BLK:US', 'BMI:US', 'BMY:US', 'BNPQY:US', 'BNTX:US', 'BOOT:US', 'BP:US', 'BR:US', 'BRK/B:US', 'BRO:US', 'BSX:US', 'BUD:US', 'BUSE:US', 'BWA:US', 'BWIN:US', 'BX:US', 'BXP:US', 'C:US', 'CACI:US', 'CADE:US', 'CAG:US', 'CAH:US', 'CALF:US', 'CARR:US', 'CAT:US', 'CB:US', 'CBOE:US', 'CBRE:US', 'CBZ:US', 'CCI:US', 'CCK:US', 'CCL:US', 'CDAY:US', 'CDNS:US', 'CDRE:US', 'CDW:US', 'CE:US', 'CEG:US', 'CELH:US', 'CENT:US', 'CF:US', 'CFG:US', 'CFRUY:US', 'CFSSX:US', 'CG:US', 'CHD:US', 'CHDN:US', 'CHE:US', 'CHGCY:US', 'CHK:US', 'CHRD:US', 'CHTR:US', 'CHUY:US', 'CHX:US', 'CI:US', 'CINF:US', 'CL:US', 'CLF:US', 'CLH:US', 'CLPBY:US', 'CLX:US', 'CM:US', 'CMA:US', 'CMCSA:US', 'CME:US', 'CMG:US', 'CMI:US', 'CMPGY:US', 'CMS:US', 'CNC:US', 'CNI:US', 'CNM:US', 'CNP:US', 'CNQ:US', 'CNTY:US', 'COCO:US', 'COF:US', 'COHR:US', 'COIN:US', 'COO:US', 'COP:US', 'COR:US', 'COST:US', 'COWZ:US', 'CP:US', 'CPB:US', 'CPRI:US', 'CPRT:US', 'CPT:US', 'CRARY:US', 'CRI:US', 'CRL:US', 'CRM:US', 'CSCO:US', 'CSGP:US', 'CSL:US', 'CSX:US', 'CTAS:US', 'CTLT:US', 'CTS:US', 'CTSH:US', 'CTVA:US', 'CVS:US', 'CVX:US', 'CWEN.A:US', 'CXDO:US', 'CYBR:US', 'CZR:US', 'D:US', 'DAL:US', 'DALCX', 'DASH:US', 'DASTY:US', 'DAVA:US', 'DB:US', 'DBSDY:US', 'DBX:US', 'DCI:US', 'DD:US', 'DDOG:US', 'DE:US', 'DECK:US', 'DELL:US', 'DEO:US', 'DFAS:US', 'DFS:US', 'DG:US', 'DGRO:US', 'DGX:US', 'DHI:US', 'DHR:US', 'DIS:US', 'DLR:US', 'DLTR:US', 'DNB:US', 'DOCU:US', 'DOV:US', 'DOW:US', 'DOX:US', 'DPZ:US', 'DRI:US', 'DSDVY:US', 'DSGX:US', 'DT:US', 'DTE:US', 'DTEGY:US', 'DTM:US', 'DUK:US', 'DVN:US', 'DWAC:US', 'DXC:US', 'DXCM:US', 'EA:US', 'EBAY:US', 'EBS:US', 'ECL:US', 'EFA:US', 'EFAD:US', 'EFC:US', 'EFX:US', 'EIX:US', 'EL:US', 'ELAN:US', 'ELF:US', 'ELV:US', 'EME:US', 'EMLP:US', 'EMN:US', 'EMR:US', 'ENLAY:US', 'ENPH:US', 'ENTG:US', 'EOG:US', 'EPAC:US', 'EPAM:US', 'EPOKY:US', 'EQH:US', 'EQIX:US', 'EQR:US', 'EQT:US', 'EQV:US', 'ES:US', 'ESTC:US', 'ET:US', 'ETN:US', 'ETR:US', 'ETSY:US', 'EW:US', 'EWA:US', 'EXC:US', 'EXPD:US', 'EXPE:US', 'EXPO:US', 'EXR:US', 'EZU:US', 'F:US', 'FANG:US', 'FANUY:US', 'FAST:US', 'FBIN:US', 'FBKWX:US', 'FCFS:US', 'FCNCA:US', 'FCNTX:US', 'FCX:US', 'FDRR:US', 'FDS:US', 'FDX:US', 'FE:US', 'FERG:US', 'FFIV:US', 'FFRHX:US', 'FI:US', 'FICO:US', 'FIS:US', 'FITB:US', 'FIX:US', 'FLJP:US', 'FLL:US', 'FLNG:US', 'FLT:US', 'FLYW:US', 'FMAO:US', 'FMC:US', 'FMCSX:US', 'FMX:US', 'FN:US', 'FNF:US', 'FOXA:US', 'FOXF:US', 'FQAL:US', 'FRO:US', 'FRPT:US', 'FSLR:US', 'FTGC:US', 'FTNT:US', 'FTV:US', 'FWONK:US', 'FWRG:US', 'G:US', 'GBCI:US', 'GBOOY:US', 'GD:US', 'GDDY:US', 'GE:US', 'GEHC:US', 'GEM:US', 'GEN:US', 'GEV:US', 'GEVO:US', 'GIC:US', 'GICIX:US', 'GIGB:US', 'GILD:US', 'GIS:US', 'GL:US', 'GLDM:US', 'GLW:US', 'GM:US', 'GMAB:US', 'GNRC:US', 'GOOGL:US', 'GPC:US', 'GPK:US', 'GPN:US', 'GRMN:US', 'GS:US', 'GSK:US', 'GTES:US', 'GTLB:US', 'GTLS:US', 'GWW:US', 'HAL:US', 'HALO:US', 'HAS:US', 'HBAN:US', 'HCA:US', 'HD:US', 'HDB:US', 'HE:US', 'HEI:US', 'HELE:US', 'HIG:US', 'HII:US', 'HIW:US', 'HKXCY:US', 'HL:US', 'HLI:US', 'HLN:US', 'HLT:US', 'HNI:US', 'HOG:US', 'HOLX:US', 'HOMB:US', 'HON:US', 'HOOD:US', 'HOPE:US', 'HPE:US', 'HPQ:US', 'HQY:US', 'HRI:US', 'HRL:US', 'HSBC:US', 'HSHCY:US', 'HSIC:US', 'HST:US', 'HSY:US', 'HTGC:US', 'HTLD:US', 'HUBB:US', 'HUBS:US', 'HUM:US', 'HWM:US', 'HYBB:US', 'IART:US', 'IBDRY:US', 'IBKR:US', 'IBM:US', 'IBN:US', 'IBP:US', 'IBUY:US', 'ICE:US', 'ICFI:US', 'ICLR:US', 'ICOW:US', 'ICUI:US', 'IDA:US', 'IDXX:US', 'IEF:US', 'IEFA:US', 'IEI:US', 'IEMG:US', 'IEX:US', 'IFF:US', 'IFNNY:US', 'IGSB:US', 'IJR:US', 'ILMN:US', 'INCY:US', 'INFN:US', 'INRE:US', 'INSM:US', 'INTC:US', 'INTU:US', 'INVA:US', 'INVH:US', 'IP:US', 'IPG:US', 'IQV:US', 'IR:US', 'IRBT:US', 'IRM:US', 'ISNPY:US', 'ISRG:US', 'IT:US', 'ITA:US', 'ITCI:US', 'ITT:US', 'ITW:US', 'IUSG:US', 'IVV:US', 'IVW:US', 'IVZ:US', 'IWB:US', 'IWM:US', 'IXNZF:US', 'J:US', 'JBHT:US', 'JBL:US', 'JCI:US', 'JKHY:US', 'JLL:US', 'JMBS:US', 'JNJ:US', 'JNPR:US', 'JPM:US', 'JTSXX:US', 'K:US', 'KDP:US', 'KEY:US', 'KEYS:US', 'KHC:US', 'KIM:US', 'KKR:US', 'KLAC:US', 'KMB:US', 'KMI:US', 'KMX:US', 'KO:US', 'KR:US', 'KVUE:US', 'L:US', 'LAZ:US', 'LBRDA:US', 'LBYAV:US', 'LDNXF:US', 'LDOS:US', 'LEA:US', 'LECO:US', 'LEG:US', 'LEN:US', 'LFUS:US', 'LGF/A:US', 'LGIH:US', 'LH:US', 'LHX:US', 'LII:US', 'LIN:US', 'LKQ:US', 'LLY:US', 'LMT:US', 'LNC:US', 'LNG:US', 'LOW:US', 'LPLA:US', 'LRCX:US', 'LRLCY:US', 'LRN:US', 'LSYIX:US', 'LUBFX:US', 'LULU:US', 'LUV:US', 'LVMHF:US', 'LVS:US', 'LW:US', 'LYB:US', 'LYV:US', 'LZB:US', 'MA:US', 'MAA:US', 'MANH:US', 'MAR:US', 'MAS:US', 'MCD:US', 'MCHP:US', 'MCK:US', 'MCO:US', 'MDB:US', 'MDLZ:US', 'MDT:US', 'MDY:US', 'MDYG:US', 'MEDP:US', 'MELI:US', 'MET:US', 'META:US', 'MFC:US', 'MGM:US', 'MHK:US', 'MHVIY:US', 'MKC:US', 'MKL:US', 'MKTX:US', 'MLM:US', 'MMC:US', 'MMM:US', 'MNST:US', 'MO:US', 'MOH:US', 'MOO:US', 'MOS:US', 'MPC:US', 'MPWR:US', 'MRAAY:US', 'MRK:US', 'MRNA:US', 'MRO:US', 'MRVL:US', 'MS:US', 'MSCI:US', 'MSFT:US', 'MSGE:US', 'MSI:US', 'MSTR:US', 'MTB:US', 'MTCH:US', 'MTD:US', 'MTDR:US', 'MTSI:US', 'MTX:US', 'MTZ:US', 'MU:US', 'MUFG:US', 'MUR:US', 'NBIX:US', 'NCLH:US', 'NCR:US', 'NDAQ:US', 'NDSN:US', 'NEE:US', 'NEM:US', 'NET:US', 'NFG:US', 'NFLX:US', 'NGD:US', 'NGG:US', 'NGL:US', 'NKE:US', 'NLY:US', 'NMVZX:US', 'NOC:US', 'NOW:US', 'NRDBY:US', 'NRG:US', 'NSC:US', 'NSIT:US', 'NSRGY:US', 'NTAP:US', 'NTDOY:US', 'NTIOF:US', 'NTNX:US', 'NTRA:US', 'NTRS:US', 'NU:US', 'NUE:US', 'NVDA:US', 'NVO:US', 'NVR:US', 'NVS:US', 'NVT:US', 'NWG:US', 'NWN:US', 'NWSA:US', 'NXPI:US', 'OC:US', 'ODFL:US', 'OKE:US', 'OKTA:US', 'OLLI:US', 'OMC:US', 'OMF:US', 'ON:US', 'ONEQ:US', 'ONEW:US', 'ORCL:US', 'ORLY:US', 'ORMP:US', 'OSK:US', 'OTIS:US', 'OXY:US', 'PANW:US', 'PARA:US', 'PAYC:US', 'PAYX:US', 'PBA:US', 'PCAR:US', 'PCG:US', 'PCLPX:US', 'PCTY:US', 'PCVX:US', 'PDBC:US', 'PDRDY:US', 'PEAK:US', 'PEG:US', 'PENN:US', 'PEP:US', 'PFE:US', 'PFG:US', 'PFGC:US', 'PG:US', 'PGNY:US', 'PGR:US', 'PH:US', 'PHM:US', 'PI:US', 'PINS:US', 'PKG:US', 'PLD:US', 'PLTR:US', 'PLXS:US', 'PM:US', 'PNC:US', 'PODD:US', 'POOL:US', 'PPBI:US', 'PPG:US', 'PPL:US', 'PRF:US', 'PRI:US', 'PRIM:US', 'PRMW:US', 'PROSY:US', 'PRU:US', 'PSA:US', 'PSTG:US', 'PSX:US', 'PTC:US', 'PTEN:US', 'PWR:US', 'PYCR:US', 'PYPL:US', 'QCOM:US', 'QQQ:US', 'QRVO:US', 'QSR:US', 'RBA:US', 'RCL:US', 'RDDT:US', 'RE:US', 'REG:US', 'REGN:US', 'RF:US', 'RGEN:US', 'RGLD:US', 'RH:US', 'RHHBY:US', 'RHI:US', 'RHP:US', 'RIO:US', 'RJF:US', 'RL:US', 'RLI:US', 'RMD:US', 'RNMBY:US', 'ROK:US', 'ROL:US', 'ROP:US', 'ROST:US', 'RPD:US', 'RPM:US', 'RRX:US', 'RSG:US', 'RTX:US', 'RUM:US', 'RVTY:US', 'RY:US', 'SAFRY:US', 'SAIA:US', 'SAIC:US', 'SAP:US', 'SBAC:US', 'SBCF:US', 'SBGSY:US', 'SBUX:US', 'SCCO:US', 'SCGLY:US', 'SCHP:US', 'SCHW:US', 'SDZNY:US', 'SE:US', 'SEAS:US', 'SF:US', 'SFM:US', 'SG:US', 'SGIOY:US', 'SGOV:US', 'SHEL:US', 'SHLS:US', 'SHOP:US', 'SHW:US', 'SHY:US', 'SIEGY:US', 'SJM:US', 'SKX:US', 'SKY:US', 'SLAB:US', 'SLB:US', 'SLYG:US', 'SLYV:US', 'SMCI:US', 'SMDV:US', 'SMFG:US', 'SNA:US', 'SNDK:US', 'SNDR:US', 'SNOW:US', 'SNPS:US', 'SNV:US', 'SNY:US', 'SO:US', 'SOFI:US', 'SOLV:US', 'SONO:US', 'SONVY:US', 'SONY:US', 'SPCE:US', 'SPDW:US', 'SPG:US', 'SPGI:US', 'SPHY:US', 'SPOT:US', 'SPXC:US', 'SPY:US', 'SPYG:US', 'SPYV:US', 'SQ:US', 'SRE:US', 'SRPT:US', 'SRVR:US', 'SSD:US', 'SSNC:US', 'ST:US', 'STAG:US', 'STE:US', 'STLD:US', 'STRL:US', 'STT:US', 'STX:US', 'STZ:US', 'SU:US', 'SUI:US', 'SUN:US', 'SUPN:US', 'SWK:US', 'SWKS:US', 'SWTX:US', 'SYF:US', 'SYIEY:US', 'SYK:US', 'SYY:US', 'T:US', 'TAK:US', 'TAP:US', 'TBLL:US', 'TBPH:US', 'TCBI:US', 'TCEHY:US', 'TCMD:US', 'TD:US', 'TDG:US', 'TDY:US', 'TEAM:US', 'TECH:US', 'TECK:US', 'TEL:US', 'TER:US', 'TFC:US', 'TFX:US', 'TGT:US', 'THR:US', 'TIMB:US', 'TJX:US', 'TKR:US', 'TLH:US', 'TLK:US', 'TM:US', 'TME:US', 'TMO:US', 'TMUS:US', 'TNC:US', 'TNDM:US', 'TOELY:US', 'TPH:US', 'TPL:US', 'TPR:US', 'TPX:US', 'TRGP:US', 'TRMB:US', 'TROW:US', 'TRS:US', 'TRV:US', 'TSCO:US', 'TSLA:US', 'TSM:US', 'TSN:US', 'TT:US', 'TTC:US', 'TTD:US', 'TTE:US', 'TTNDY:US', 'TTWO:US', 'TW:US', 'TWLO:US', 'TXN:US', 'TXRH:US', 'TXT:US', 'TYL:US', 'UAL:US', 'UBER:US', 'UBS:US', 'UCTT:US', 'UDR:US', 'UFPI:US', 'UHS:US', 'UL:US', 'ULTA:US', 'UMBF:US', 'UNCRY:US', 'UNH:US', 'UNICY:US', 'UNP:US', 'UPS:US', 'URA:US', 'URI:US', 'USB:US', 'USFD:US', 'USPH:US', 'UTHR:US', 'UTZ:US', 'V:US', 'VAW:US', 'VCISY:US', 'VEA:US', 'VEEV:US', 'VIA:US', 'VIAV:US', 'VICI:US', 'VIG:US', 'VIK:US', 'VLO:US', 'VLTO:US', 'VMC:US', 'VMFXX:US', 'VNQ:US', 'VO:US', 'VOO:US', 'VOYA:US', 'VRIG:US', 'VRSK:US', 'VRSN:US', 'VRT:US', 'VRTX:US', 'VSAT:US', 'VSH:US', 'VST:US', 'VTI:US', 'VTR:US', 'VTRS:US', 'VTV:US', 'VVV:US', 'VWLUX:US', 'VWO:US', 'VZ:US', 'WAB:US', 'WAL:US', 'WAT:US', 'WBA:US', 'WBD:US', 'WBS:US', 'WDAY:US', 'WDC:US', 'WEC:US', 'WELL:US', 'WFC:US', 'WM:US', 'WMB:US', 'WMS:US', 'WMT:US', 'WRB:US', 'WRK:US', 'WSC:US', 'WST:US', 'WTM:US', 'WTW:US', 'WU:US', 'WWD:US', 'WY:US', 'XEL:US', 'XLE:US', 'XMHQ:US', 'XNGSY:US', 'XOM:US', 'XONE:US', 'XP:US', 'XRAY:US', 'XYL:US', 'YUM:US', 'ZBH:US', 'ZBRA:US', 'ZION:US', 'ZM:US', 'ZROZ:US', 'ZS:US', 'ZTS:US']\n"
     ]
    }
   ],
   "source": [
    "unique_tickers = sorted(df['traded_issuer_ticker'].dropna().unique().tolist())\n",
    "print(unique_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ReadTimeout",
     "evalue": "HTTPSConnectionPool(host='stockanalysis.com', port=443): Read timed out. (read timeout=30)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/connectionpool.py:537\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 537\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/connection.py:466\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/http/client.py:1395\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1395\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1396\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/http/client.py:325\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 325\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/http/client.py:286\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 286\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/ssl.py:1314\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1311\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1312\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1313\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/ssl.py:1166\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mTimeoutError\u001b[0m: The read operation timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/connectionpool.py:847\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    845\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 847\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    850\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/util/retry.py:470\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_method_retryable(method):\n\u001b[0;32m--> 470\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/util/util.py:39\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/connectionpool.py:793\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 793\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/connectionpool.py:539\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 539\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/connectionpool.py:370\u001b[0m, in \u001b[0;36mHTTPConnectionPool._raise_timeout\u001b[0;34m(self, err, url, timeout_value)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, SocketTimeout):\n\u001b[0;32m--> 370\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;28mself\u001b[39m, url, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead timed out. (read timeout=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;66;03m# See the above comment about EAGAIN in Python 3.\u001b[39;00m\n",
      "\u001b[0;31mReadTimeoutError\u001b[0m: HTTPSConnectionPool(host='stockanalysis.com', port=443): Read timed out. (read timeout=30)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 55\u001b[0m\n\u001b[1;32m     53\u001b[0m results \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, tk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(chunk5_tickers, \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 55\u001b[0m     results[tk] \u001b[38;5;241m=\u001b[39m \u001b[43mget_sector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:                    \u001b[38;5;66;03m# pause every 10 requests\u001b[39;00m\n\u001b[1;32m     57\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(random\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n",
      "Cell \u001b[0;32mIn[10], line 19\u001b[0m, in \u001b[0;36mget_sector\u001b[0;34m(ticker)\u001b[0m\n\u001b[1;32m     17\u001b[0m stock_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://stockanalysis.com/stocks/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 19\u001b[0m     html \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstock_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mraise_for_status() \u001b[38;5;129;01mor\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mget(stock_url, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _parse_sector(html)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/adapters.py:532\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ReadTimeoutError):\n\u001b[0;32m--> 532\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeout(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, _InvalidHeader):\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidHeader(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[0;31mReadTimeout\u001b[0m: HTTPSConnectionPool(host='stockanalysis.com', port=443): Read timed out. (read timeout=30)"
     ]
    }
   ],
   "source": [
    "#SCRAPING FROM STOCK ANALYSIS\n",
    "# ------------------------- helper -------------------------\n",
    "def _parse_sector(html):\n",
    "    soup  = BeautifulSoup(html, \"html.parser\")\n",
    "    label = soup.find(\"span\", string=\"Sector\")\n",
    "    if label:\n",
    "        tag = label.find_next(\"a\", class_=\"dothref text-default\")\n",
    "        if tag:\n",
    "            return tag.text.strip()\n",
    "    return \"Sector not found\"\n",
    "\n",
    "# ------------------------- main ---------------------------\n",
    "def get_sector(ticker):\n",
    "    base = ticker.split(\":\")[0].lower().replace(\"/\", \".\")  # Convert slashes to dots for URL compatibility\n",
    "\n",
    "    # 1) try exchange-listed stock\n",
    "    stock_url = f\"https://stockanalysis.com/stocks/{base}/\"\n",
    "    try:\n",
    "        html = requests.get(stock_url, timeout=30).raise_for_status() or requests.get(stock_url, timeout=30).text\n",
    "        return _parse_sector(html)\n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        if err.response is None or err.response.status_code != 404:\n",
    "            return f\"Error: {err}\"\n",
    "\n",
    "    # 2) try ETF  ➜ return None (always unrelated)\n",
    "    etf_url = f\"https://stockanalysis.com/etf/{base}/\"\n",
    "    try:\n",
    "        requests.get(etf_url, timeout=30).raise_for_status()\n",
    "        return None\n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        if err.response is None or err.response.status_code != 404:\n",
    "            return f\"Error: {err}\"\n",
    "\n",
    "    # 3) try OTC stock\n",
    "    otc_url = f\"https://stockanalysis.com/quote/otc/{base}/\"\n",
    "    try:\n",
    "        html = requests.get(otc_url, timeout=30).raise_for_status() or requests.get(otc_url, timeout=30).text\n",
    "        return _parse_sector(html)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "\n",
    "# Removing crypto\n",
    "tickers = unique_tickers[10:]\n",
    "\n",
    "#Splitting into ticker chunks for scraping timeouts... 1 -> [0:300] , 2 -> [300:600], <TODO LATER>\n",
    "chunk1_tickers = tickers[0:300]\n",
    "chunk2_tickers = tickers[283:500] #Starting at 283, since 284 failed.\n",
    "chunk3_tickers = tickers[462:600] #Same reason as above\n",
    "chunk4_tickers = tickers[600:800]\n",
    "chunk5_tickers = tickers[798:]\n",
    "\n",
    "results = {}\n",
    "for i, tk in enumerate(chunk5_tickers, 1):\n",
    "    results[tk] = get_sector(tk)\n",
    "    if i % 10 == 0:                    # pause every 10 requests\n",
    "        time.sleep(random.uniform(2, 4))\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: associate congressman with industry\n",
    "# Convert sector scraping results into DataFrame\n",
    "sector_df = pd.DataFrame(list(results.items()), columns=['ticker', 'sector'])\n",
    "\n",
    "# Merge sector info into the paired trade data\n",
    "pair_df = pair_df.merge(sector_df, on='ticker', how='left')\n",
    "\n",
    "# Group by Congressperson and sector, count number of trades per sector\n",
    "top_sectors = (\n",
    "    pair_df.groupby(['politician_name', 'sector'])\n",
    "    .size()\n",
    "    .reset_index(name='num_trades')\n",
    "    .sort_values(['politician_name', 'num_trades'], ascending=[True, False])\n",
    ")\n",
    "\n",
    "# Optional: Get top sector per Congressperson\n",
    "top_sector_per_person = top_sectors.groupby('politician_name').first().reset_index()\n",
    "\n",
    "# Print result\n",
    "print(top_sector_per_person.head())\n",
    "\n",
    "# Save to CSV if desired\n",
    "top_sector_per_person.to_csv('congressperson_top_sectors.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Thoughtful discussion of ethical concerns included\n",
    "- Ethical concerns consider the whole data science process (question asked, data collected, data being used, the bias in data, analysis, post-analysis, etc.)\n",
    "- How your group handled bias/ethical concerns clearly described\n",
    "\n",
    "Acknowledge and address any ethics & privacy related issues of your question(s), proposed dataset(s), and/or analyses. Use the information provided in lecture to guide your group discussion and thinking. If you need further guidance, check out [Deon's Ethics Checklist](http://deon.drivendata.org/#data-science-ethics-checklist). In particular:\n",
    "\n",
    "- Are there any biases/privacy/terms of use issues with the data you propsed?\n",
    "- Are there potential biases in your dataset(s), in terms of who it composes, and how it was collected, that may be problematic in terms of it allowing for equitable analysis? (For example, does your data exclude particular populations, or is it likely to reflect particular human biases in a way that could be a problem?)\n",
    "- How will you set out to detect these specific biases before, during, and after/when communicating your analysis?\n",
    "- Are there any other issues related to your topic area, data, and/or analyses that are potentially problematic in terms of data privacy and equitable impact?\n",
    "- How will you handle issues you identified?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our response:\n",
    "\n",
    "Some of our ethical concerns:\\n\n",
    "Could it be slanderous/libelous to imply that specific politicians participate in insider trading?\n",
    "Does a strong correlation even imply insider trading in the first place, or is someone who is on that committee more predisposed to being knowledgeable about the field? (correlation vs causation)\n",
    "How would the accusation of insider trading affect a political candidate?\n",
    "How can we control the framing of our results such that they cannot be co-opted to be used to claim corruption when it does not exist?\n",
    "Probably use web scraping to obtain data - might be against certain site TOS.\n",
    "Privacy: If you are a politician (as a public official), do you have as much a right to privacy as a citizen?\\\n",
    "\n",
    "Bias in data:\n",
    "Congress demographically is not an accurate representation of the United States population\n",
    "Some industries may be more “tightly-knit” than others that we may unknowingly include/exclude\n",
    "Research: what industries have the biggest “revolving door” (where lobbyists become politicians and politicians become lobbyists)\n",
    "Are there timeline changes that might skew our data? (STOCK Act, depends on the administration/Current attorney general & willingness of persecution)\n",
    "Missing data?\n",
    "Are we doing this for something good or is it for personal gain?\n",
    "Could potentially be good to point out corruption, if our hypothesis is true. \\\n",
    "\n",
    "We will handle our ethical concerns as follows:\\\n",
    "Regarding all the concerns mentioned above, post-analysis, it should be made clear regardless of the findings that this research project should not be a guideline as to whether you should or should not follow the stock market actions of politicians… as we are not financial professionals. Furthermore, our limitations (new and old) should be made clear to readers at the beginning and end of our project to indicate where shortcomings in our data analysis could stem from. We will make it intentionally and specifically clear the aim of our project is not to determine if insider trading is occurring as a whole or at an individual level as we do not want to slander anyone. Especially considering this is purely observational data, meaning we can only infer correlation (if any) and not causation between politicians, their commitee/sector, and trading. \\\n",
    "\n",
    "In terms of biases, privacy, and terms of use issues, Congresspeople are generally mandated to include investments in their financial self-reports, and are not subject to the same expectations of privacy that private citizens are. However, individual sites that we take data from may object to the use of data in a study like this, and it may be against their terms of use to scrape data from their site.\\\n",
    "\n",
    "In terms of biases in our dataset, if we are not careful about making sure our committees monitored are representative of Congress, some committees and industries may have more of a “revolving door” effect than others depending on how powerful and funded the related lobbying firms and special interests are. We already know that the Senate has a more powerful “revolving door” than the House does, so we must also balance the amount of Senate and House data such that the results are not skewed in a particular direction, leading us to over- or under-estimate the amount of correlation there is.\\\n",
    "\n",
    "We will detect biases as follows. We should have a test dataset to perform EDA on and gain an intuition about how connections in the data normally look. Then, we should analyze the similarities and differences in our test dataset and study dataset, and compare how our hypotheses differ according to these similarities and differences. Therefore, we can determine if one, or both of our datasets are skewed in some manner, as two incredibly similar datasets may indicate both are skewed, and two very different datasets may indicate one is skewed.\\\n",
    "\n",
    "In terms of data privacy and equitable impact, the main concern is of our results being co-opted for libelous means. Congresspeople are public officials and are required by law to publicly self-report their financial information, so there is not as much of a concern about data privacy. And most congresspeople are difficult to describe as “disadvantaged,” so the ability of causing equitable impact is minimized.\\\n",
    "\n",
    "We will handle isuses by checking terms of service and talk with the TAs about how to collect this data in an ethical way, and whether scraping will be permitted for this project. Also, we will make sure to collect a variety of datasets, and compare the dataset against itself and against other samples in order to determine how to construct the most representative sample.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Read over the [COGS108 Team Policies](https://github.com/COGS108/Projects/blob/master/COGS108_TeamPolicies.md) individually. Then, include your group’s expectations of one another for successful completion of your COGS108 project below. Discuss and agree on what all of your expectations are. Discuss how your team will communicate throughout the quarter and consider how you will communicate respectfully should conflicts arise. By including each member’s name above and by adding their name to the submission, you are indicating that you have read the COGS108 Team Policies, accept your team’s expectations below, and have every intention to fulfill them. These expectations are for your team’s use and benefit — they won’t be graded for their details.\n",
    "\n",
    "* *Team Expectation 1*\n",
    "* *Team Expectation 2*\n",
    "* *Team Expecation 3*\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our team expectations:\n",
    "* Team Expectation 1: Timely responses to messages via discord (or text) within 16-24 hours.\n",
    "* Team Expectation 2: Fair and Equitable distribution of work.\n",
    "* Team Expectation 3: Acknowledgement of all outside sources/external tools used in completion of work\n",
    "* Team Expectation 4: Create work that is impactful, and clear to understand\n",
    "* Team Expectation 5: Maintain ethics in regards to data privacy, data collection, etc.\n",
    "* Team Expectation 6: If we believe we will miss a deadline, try to notify the group 24+ hours in advance, or at minimum 12 hours in advance\n",
    "* Team Expectation 7: Don't let questions build up - if we have a question, others probably do as well. Asking questions is what will keep us honest and maintain our consensus.\n",
    "* Team Expectation 8: Compassion builds cooperation - try to be understanding of one another's life situations. Furthermore, we all entered with different levels of skill, and we should maintain a growth mindset, giving each other energy to always improve.\n",
    "* Team Expectation 9: Quality first! Always strive to follow best practices in data science.\n",
    "* Team Expectation 10: Choose technologies that are applicable to our model, rather than what's popular (ex: if it doesn't make sense to use an LLM, then we shouldn't use one for regression)\n",
    "* Team Expectation 11: If we ever have a disagreement, we should discuss in front of the entire group and try to reach a consensus. It is not enough to have majority rule, or rule by force, we must have compromise and consensus.\n",
    "* Team Expectation 12: If we feel like someone isn't contributing as much, or some people are assigned too much work, we can meet as a group and redistribute the tasks in a fair and equitable manner.\n",
    "* Team Expectation 13: Blame problems on systems, not people. Always ask how we can restructure our group to improve the quality of work and the comfort of the social dynamic.\n",
    "* Team Expectation 14: If we have repeated issues with something, are our methods and values flawed, and how should we revise them to solve/avoid these issues?\n",
    "* Team Expectation 15: We will hold a weekly sprint planning, to go over what we've accomplished, and plan what we need to do next in order to continue the project, as well as identify any blockers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify your team's specific project timeline. An example timeline has been provided. Changes the dates, times, names, and details to fit your group's plan.\n",
    "\n",
    "If you think you will need any special resources or training outside what we have covered in COGS 108 to solve your problem, then your proposal should state these clearly. For example, if you have selected a problem that involves implementing multiple neural networks, please state this so we can make sure you know what you’re doing and so we can point you to resources you will need to implement your project. Note that you are not required to use outside methods.\n",
    "\n",
    "\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 4/22  |  8 PM | Read & Think about COGS 108 expectations; brainstorm topics/questions  | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis; begin background research | \n",
    "| 4/28  |  8 PM |  Do background research on topic | Discuss ideal dataset(s) and ethics; draft project proposal | \n",
    "| 4/29  | 12 PM  | Edit, finalize, and submit proposal; Search for datasets  | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 05/07  | 8PM  | Import & Wrangle Data (Tyler, Manjot) | Review/Edit wrangling/EDA; Discuss Analysis Plan (All hands)  |\n",
    "| 05/16 | 8PM | Finish wrangling dataset #1 (Tyler, Tanner, Thanh), begin EDA (David, Manjot)\n",
    "| 05/19  | 8PM  | Finalize wrangling/EDA (Tanner, Thanh, David); Begin Analysis (Tyler; Manjot, Tanner) | Discuss/edit Analysis; Complete project check-in |\n",
    "| 05/24 | 8PM | Preliminary Analysis & Assigned Tasks (Tyler, Thanh) | Plan & delegate more detailed analysis (Tanner, Manjot, David) |\n",
    "| 05/28  | 8PM  | Complete analysis; Draft results/conclusion/discussion (Thanh, David)| Discuss/edit full project (all hands) |\n",
    "| 06/04  | 8PM  | Project is Finished | Turn in Final Project & Group Project Surveys |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
